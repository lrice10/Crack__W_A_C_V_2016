

\section{Introduction}
Periodic inspection is important to ensure the safety of nuclear power plant components. Manually inspecting and evaluating 100+ hours of video for rarely occurring cracks is a tedious process. However, automatic inspection is challenging as the images often contain highly textured area including weld and concrete surface which causes fragmented and noisy segmentations.

Koch et. al \cite{koch2015review_survey} review the different methods for detecting defects civil infrastructures. They summarize the different methods of crack detection in the domains of reinforced concrete bridges, precast concrete tunnels, underground concrete pipes, and asphalt pavements. They generalize that all the methods usually have two steps, pre-processing, and crack-identification. The pre-processing involves extracting features from lines or edges. They categorize crack-identification step into 3 categories, threshold-based, model-based, and pattern-based approaches. 

Recently, several methods for automatic crack detection have been proposed to address the challenges of non-crack noises and crack intensity discontinuity. Segment extending [\cite{SEG_EXTEND}], tensor voting [\cite{ZouTensorVoting}], and extending a saliency map [SALIENCY] have been applied to connect disconnected cracks. A block SVM classifier using soft hough features was used to detect cracks in noisy images [\cite{HTF_SVM}]. Seed growing [\cite{SEED_GROW}] and crack saliency [\cite{SALIENCY}] using statistical features have also been applied to reduce detecting noise as crack. Jahanshahi et al. segment line-like segments using morphological operations, extract geometric features from the segments and then use a neural network classifier to determine if the segment is a crack [\cite{jahanshahi2013innovative}].

Hand crafted features and machine learning classifiers have been used to detect cracks. A block SVM classifier using soft hough features was used to detect cracks in noisy images HTF-SVM. Oliveira et. al develop a system to detect road cracks using an unsupervised learning method \cite{Oliveira2013_road_blockClassification} \cite{Oliveira2014_Road_Classify_ICIP}.  Gabor features along with an adaboost classifier are used to detect road cracks \cite{Medina2014_Road_GaborAdaboost}.  Chanda et. al  detect cracks in highly textured bridges using texture features and SVM \cite{chanda2014_bridges_textureSVM}. Kapela et. al. detect asphalt using HOG and a SVM classifier \cite{Kapela2015_Road_HOG_SVM}. Prasanna et. al. divide the image into blocks, detect lines using RANSAC in each block, extract gradient and intensity features from the block at different scales and then classify the block as crack or not using a classifier \cite{Prasanna2014_Bridges_classifierRANSAClines}. Jahanshahi et al. segment line-like segments using morphological operations, extract geometric features from the segments and then use a neural network classifier to determine if the segment is a crack \cite{jahanshahi2013innovative}. 

Zou et. al detect defects in weld pipe inspection videos by using a Kalman filter to detect the continuity of the defect motion as compared to just noise detections.   \cite{Zou2015_weldDefect_Kalman}


Convolutional Neural Networks and modern GPUs have brought great success in object classification in recent years with the monumental success of Alexnet in the 2012 ImageNet competition \cite{krizhevsky2012imagenet}.  The deeper but less parameters GoogLeNet CNN performed the best in the 2014 ImageNet Competition \cite{googlenet2014going}. Instead of hand crafting features, the CNN learns features that are useful to the object classification task. The Deep Learning CNNs learned in the multi-class object classification can be fine tuned to other tasks such as face detection \cite{farfade2015multi} and style classification \cite{karayev2013styleRecognizing}.

In this paper, we propose to improve the detection of cracks by (1) fine-tuning the GoogLeNet convolutional neural network for crack block classification, and (2) group the detected crack patches by fitting planes in the spatial-temporal space (x,y,time). Testing on 17 real videos demonstrates accuracy of XX TP and XX FP rates which is XX\% improvement over prior method. Testing of 42 real images demonstrates 38% improvement over prior method. Note that the evaluation of the method is conducted at the classification of image level rather than the segmentation at pixel-level.


